{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Import packages needed\nimport os\nimport subprocess\n\ncwd = os.getcwd()\n\n# Clone the repository\nrepository_url = \"https://github.com/Xpehutta/llm4sql.git\"\ndestination_folder = cwd + \"/llm4sql\"\n\n# Ensure the destination folder does not already exist\nif os.path.exists(destination_folder):\n    print(f\"Destination folder {destination_folder} already exists.\")\nelse:\n    try:\n        # Run the git clone command\n        subprocess.run([\"git\", \"clone\", repository_url, destination_folder], check=True)\n        print(f\"Repository cloned successfully to {destination_folder}\")\n    except subprocess.CalledProcessError as e:\n        print(f\"An error occurred while cloning the repository: {e}\")\n\n# Define the source and destination directories\nsource_dir = cwd +'/llm4sql/data-model-generator'\ndestination_dir = cwd +'/llm4sql/data_model_generator'\n\n# Step 1: Verify that the source directory exists\nif not os.path.exists(source_dir):\n    print(f\"Source directory {source_dir} does not exist.\")\n    exit(1)\n\n# Step 2: Rename the directory using os.rename\ntry:\n    os.rename(source_dir, destination_dir)\n    print(f\"Successfully renamed {source_dir} to {destination_dir}\")\nexcept OSError as e:\n    print(f\"An error occurred while renaming the directory: {e}\")\n\n# Optional: Verify that the destination directory exists\nif os.path.exists(destination_dir):\n    print(f\"Destination directory {destination_dir} exists.\")\nelse:\n    print(f\"Destination directory {destination_dir} does not exist.\")\n\n# Define the source and destination directories\ndestination_dir = destination_folder + '/data_model_generator'\n\n# Change the current working directory to the requered one\ntry:\n    os.chdir(destination_dir)\n    print(f\"Changed directory to {os.getcwd()}\")\nexcept OSError as e:\n    print(f\"An error occurred while changing directory: {e}\")\n    exit(1)\n\n# Step 4: Install the package using pip with the requirements.txt file\nrequirements_file = 'requirements.txt'\nif os.path.exists(requirements_file):\n    try:\n        subprocess.run(['pip', 'install', '-q', '-r', requirements_file], check=True)\n        print(\"Dependencies installed successfully.\")\n    except subprocess.CalledProcessError as e:\n        print(f\"An error occurred while installing dependencies: {e}\")\nelse:\n    print(f\"No {requirements_file} found. Skipping installation of dependencies.\")\n\n# Return to current working directory \ntry:\n    os.chdir(cwd)\n    print(f\"Changed directory to {os.getcwd()}\")\nexcept OSError as e:\n    print(f\"An error occurred while changing directory: {e}\")\n    exit(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:15:28.346462Z","iopub.execute_input":"2025-02-14T05:15:28.346764Z","iopub.status.idle":"2025-02-14T05:15:42.226098Z","shell.execute_reply.started":"2025-02-14T05:15:28.346721Z","shell.execute_reply":"2025-02-14T05:15:42.225262Z"}},"outputs":[{"name":"stdout","text":"Repository cloned successfully to /kaggle/working/llm4sql\nSuccessfully renamed /kaggle/working/llm4sql/data-model-generator to /kaggle/working/llm4sql/data_model_generator\nDestination directory /kaggle/working/llm4sql/data_model_generator exists.\nChanged directory to /kaggle/working/llm4sql/data_model_generator\nDependencies installed successfully.\nChanged directory to /kaggle/working\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import sqlglot\nimport sqlglot.expressions as exp\nfrom Levenshtein import distance as levenshtein_distance\nfrom collections import defaultdict\n\nfrom faker import Faker\n\nimport pandas as pd\nimport numpy as np\nimport random\nimport time\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import AdamW\n\nfrom peft import LoraConfig, get_peft_model, TaskType\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm\nfrom joblib import Parallel, delayed\n\nfrom llm4sql.data_model_generator.src.data_model_generator import *\nfrom llm4sql.data_model_generator.src.sql_l_rouge import *\nfrom llm4sql.data_model_generator.src.sql_similarity import *\nfrom llm4sql.data_model_generator.model.create_data_model_excel import *","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:15:42.227085Z","iopub.execute_input":"2025-02-14T05:15:42.227395Z","iopub.status.idle":"2025-02-14T05:16:21.328772Z","shell.execute_reply.started":"2025-02-14T05:15:42.227369Z","shell.execute_reply":"2025-02-14T05:16:21.328118Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data_model = DataModelExcel()\ndata_model.create_data_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:16:21.330355Z","iopub.execute_input":"2025-02-14T05:16:21.330968Z","iopub.status.idle":"2025-02-14T05:16:22.009176Z","shell.execute_reply.started":"2025-02-14T05:16:21.330940Z","shell.execute_reply":"2025-02-14T05:16:22.008460Z"}},"outputs":[{"name":"stdout","text":"Data model created successfully: data_model.xlsx\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"generator = DataModelGenerator()\ngenerator.load_data_model()\ndataset, queries = generator.generate_dataset(num_queries=5000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:16:22.010228Z","iopub.execute_input":"2025-02-14T05:16:22.010753Z","iopub.status.idle":"2025-02-14T05:16:29.094646Z","shell.execute_reply.started":"2025-02-14T05:16:22.010709Z","shell.execute_reply":"2025-02-14T05:16:29.093936Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"sql_queries = list(queries['queries'])\n\n# Example usage\nsimilarity = SQLSimilarity()\nquery1 = sql_queries[0]\nquery2 = sql_queries[4999]\n\nprint(query1, '\\n')\nprint(query2)\n\n# Normalize queries\nnorm1 = similarity.normalize_query(query1)\nnorm2 = similarity.normalize_query(query2)\n\n# Calculate similarities\nif norm1 and norm2:\n    ast_sim = similarity.ast_similarity(norm1, norm2)\n    component_sim = similarity.component_similarity(norm1, norm2)\n    print(f\"\\nAST Similarity: {ast_sim:.2f}\")\n    print(\"Component Similarities:\")\n    for k, v in component_sim.items():\n        print(f\"  {k}: {v:.2f}\")\n    \n    # Combined similarity score (custom weights)\n    combined_score = (\n        0.4 * ast_sim + \n        0.3 * component_sim.get(\"tables\", 0) +\n        0.2 * component_sim.get(\"columns\", 0) +\n        0.1 * component_sim.get(\"conditions\", 0)\n    )\n    print(f\"\\nCombined Similarity Score: {combined_score:.2f}\")\nelse:\n    print(\"\\nError in query normalization\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:16:29.095537Z","iopub.execute_input":"2025-02-14T05:16:29.095890Z","iopub.status.idle":"2025-02-14T05:16:29.110787Z","shell.execute_reply.started":"2025-02-14T05:16:29.095857Z","shell.execute_reply":"2025-02-14T05:16:29.110026Z"}},"outputs":[{"name":"stdout","text":"SELECT *\nFROM followers\n JOIN customers ON followers.user_id = customers.customer_id\nWHERE customers.customer_id = 760 AND customers.name = True; \n\nSELECT activity_id, activity_type\nFROM activity_logs\nWHERE activity_logs.activity_id = 371 AND activity_logs.activity_type = False;\n\nAST Similarity: 0.61\nComponent Similarities:\n  conditions: 0.00\n  tables: 0.00\n  columns: 0.00\n\nCombined Similarity Score: 0.25\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"N = 100\n# Precompute normalized queries for all SQL queries\nnormalized_queries = [similarity.normalize_query(q) for q in sql_queries[:N]]\n\n# Helper function to compute pairwise similarities for a single query\ndef compute_row(norm1, normalized_queries):\n    ast_scores = [similarity.ast_similarity(norm1, norm2) for norm2 in normalized_queries]\n    tables_scores = [similarity.component_similarity(norm1, norm2).get(\"tables\", 0) for norm2 in normalized_queries]\n    columns_scores = [similarity.component_similarity(norm1, norm2).get(\"columns\", 0) for norm2 in normalized_queries]\n    conditions_scores = [similarity.component_similarity(norm1, norm2).get(\"conditions\", 0) for norm2 in normalized_queries]\n    return ast_scores, tables_scores, columns_scores, conditions_scores\n\n# Parallel computation of rows\nresults = Parallel(n_jobs=-1)(delayed(compute_row)(norm1, normalized_queries) \n                              for norm1 in normalized_queries)\n\n# Unpack results into separate matrices\nast_matrix = np.array([row[0] for row in results])\ntables_matrix = np.array([row[1] for row in results])\ncolumns_matrix = np.array([row[2] for row in results])\nconditions_matrix = np.array([row[3] for row in results])\n\n# Combine matrices using weighted sum\ncombined_matrix = (\n    0.4 * ast_matrix +\n    0.3 * tables_matrix +\n    0.2 * columns_matrix +\n    0.1 * conditions_matrix\n)\n\n# Convert the result to a DataFrame\nsimilarity_df = pd.DataFrame(combined_matrix, index=sql_queries[:N], columns=sql_queries[:N])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:16:29.111536Z","iopub.execute_input":"2025-02-14T05:16:29.111844Z","iopub.status.idle":"2025-02-14T05:16:59.426030Z","shell.execute_reply.started":"2025-02-14T05:16:29.111810Z","shell.execute_reply":"2025-02-14T05:16:59.424988Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"pd.DataFrame(similarity_df.iloc[0]).sort_values(by = [similarity_df.columns[0]], ascending=False).head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:16:59.426971Z","iopub.execute_input":"2025-02-14T05:16:59.427264Z","iopub.status.idle":"2025-02-14T05:16:59.450397Z","shell.execute_reply.started":"2025-02-14T05:16:59.427239Z","shell.execute_reply":"2025-02-14T05:16:59.449660Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                    SELECT *\\nFROM followers\\n JOIN customers ON followers.user_id = customers.customer_id\\nWHERE customers.customer_id = 760 AND customers.name = True;\nSELECT *\\nFROM followers\\n JOIN customers ON fo...                                           1.000000                                                                                                   \nSELECT *\\nFROM followers\\nLEFT JOIN customers O...                                           0.865714                                                                                                   \nSELECT *\\nFROM orders\\nLEFT JOIN customers ON o...                                           0.633333                                                                                                   \nSELECT *\\nFROM feedbacks\\n JOIN customers ON fe...                                           0.629524                                                                                                   \nSELECT *\\nFROM messages\\n JOIN customers ON mes...                                           0.600000                                                                                                   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SELECT *\\nFROM followers\\n JOIN customers ON followers.user_id = customers.customer_id\\nWHERE customers.customer_id = 760 AND customers.name = True;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SELECT *\\nFROM followers\\n JOIN customers ON followers.user_id = customers.customer_id\\nWHERE customers.customer_id = 760 AND customers.name = True;</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>SELECT *\\nFROM followers\\nLEFT JOIN customers ON followers.user_id = customers.customer_id\\nWHERE customers.name = False AND customers.customer_id = 80;</th>\n      <td>0.865714</td>\n    </tr>\n    <tr>\n      <th>SELECT *\\nFROM orders\\nLEFT JOIN customers ON orders.customer_id = customers.customer_id\\nWHERE orders.customer_id = 183 AND customers.name = True;</th>\n      <td>0.633333</td>\n    </tr>\n    <tr>\n      <th>SELECT *\\nFROM feedbacks\\n JOIN customers ON feedbacks.customer_id = customers.customer_id\\nWHERE feedbacks.customer_id &gt; 347 AND customers.name = True;</th>\n      <td>0.629524</td>\n    </tr>\n    <tr>\n      <th>SELECT *\\nFROM messages\\n JOIN customers ON messages.sender_id = customers.customer_id\\nWHERE messages.sender_id = 952 AND customers.name = False;</th>\n      <td>0.600000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:16:59.452623Z","iopub.execute_input":"2025-02-14T05:16:59.452878Z","iopub.status.idle":"2025-02-14T05:16:59.462377Z","shell.execute_reply.started":"2025-02-14T05:16:59.452857Z","shell.execute_reply":"2025-02-14T05:16:59.461802Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#from datasets import load_metric\nmodel_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\nlora_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,\n    inference_mode=False,\n    r=4,  # Rank of the LoRA matrices\n    lora_alpha=32,  # Scaling factor for LoRA weights\n    lora_dropout=0.1  # Dropout for LoRA layers\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n\nclass SQLDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length=128):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data.iloc[idx]\n        input_text = item[\"input\"]\n        output_text = item[\"output\"]\n\n        full_text = f\"{input_text} -> {output_text}\"\n        tokenized = self.tokenizer(full_text, padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n\n        return {\n            \"input_ids\": tokenized[\"input_ids\"].squeeze(),\n            \"attention_mask\": tokenized[\"attention_mask\"].squeeze(),\n            \"labels\": tokenized[\"input_ids\"].squeeze()\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:16:59.463386Z","iopub.execute_input":"2025-02-14T05:16:59.463658Z","iopub.status.idle":"2025-02-14T05:18:11.260541Z","shell.execute_reply.started":"2025-02-14T05:16:59.463635Z","shell.execute_reply":"2025-02-14T05:18:11.259649Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.87k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"834f7daa9eea4a939dafef6775385717"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b74e771d4445059e14fee5ddbd9f3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec7f1a39535644ac9b6ec9410779fa5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.69G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3366ef1d2cf44d94af1d6b4ad92bebea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"270e0ab34ebe41feba46bae7d1b4b789"}},"metadata":{}},{"name":"stdout","text":"trainable params: 786,432 || all params: 1,347,258,368 || trainable%: 0.0584\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Assuming `dataset` is your original dataset (list of dictionaries or similar structure)\n# Split the dataset into training and validation sets\ntrain_dataset, val_dataset = train_test_split(dataset[['input', 'output']], test_size=0.1, random_state=42, stratify = dataset['group'])\n\n# Create DataLoaders for training and validation\nsql_dataset_train = SQLDataset(train_dataset, tokenizer, max_length=128)\nsql_dataset_val = SQLDataset(val_dataset, tokenizer, max_length=128)\n\ntrain_dataloader = DataLoader(sql_dataset_train, batch_size=4, shuffle=True)\nval_dataloader = DataLoader(sql_dataset_val, batch_size=4, shuffle=False)\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5, no_deprecation_warning=True)\n\n# Training loop\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:18:11.261815Z","iopub.execute_input":"2025-02-14T05:18:11.262271Z","iopub.status.idle":"2025-02-14T05:18:13.053910Z","shell.execute_reply.started":"2025-02-14T05:18:11.262230Z","shell.execute_reply":"2025-02-14T05:18:13.052724Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Initialize the SQLRougeL class\nsql_rouge = SQLRougeL()\n\n\n# Start overall timer\noverall_start_time = time.time()\n\nfor epoch in range(3):  # Number of epochs\n    epoch_start_time = time.time()\n    \n    # Training phase\n    model.train()\n    total_train_loss = 0\n    for batch in train_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_train_loss += loss.item()\n    avg_train_loss = total_train_loss / len(train_dataloader)\n    print(f\"Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}\")\n    \n    # End of training phase timer\n    train_end_time = time.time()\n    train_duration = train_end_time - epoch_start_time\n    print(f\"Epoch {epoch + 1}, Training Duration: {train_duration:.2f} seconds\")\n    \n    # Validation phase\n    model.eval()\n    total_val_loss = 0\n    total_rouge_l_f1 = 0\n    total_queries = 0\n    with torch.no_grad():\n        for batch in val_dataloader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n            loss = outputs.loss\n            total_val_loss += loss.item()\n            # Generate predictions\n            generated_tokens = model.generate(\n                input_ids=batch['input_ids'],\n                attention_mask=batch['attention_mask'],\n                max_length=256,\n                num_return_sequences=1,\n                pad_token_id=tokenizer.pad_token_id,\n                eos_token_id=tokenizer.eos_token_id,\n                do_sample=False  # Deterministic generation for evaluation\n            )\n            generated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n            reference_text = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n            for gen_query, ref_query in zip(generated_text, reference_text):\n                total_queries += 1\n                # Compute ROUGE-L-SQL\n                metrics = sql_rouge.rouge_l_sql(gen_query, ref_query)\n                total_rouge_l_f1 += metrics['f1_score']\n    avg_val_loss = total_val_loss / len(val_dataloader)\n    avg_rouge_l_f1 = total_rouge_l_f1 / total_queries if total_queries > 0 else 0\n    print(f\"Epoch {epoch + 1}, Validation Loss: {avg_val_loss:.4f}\")\n    print(f\"Epoch {epoch + 1}, ROUGE-L-SQL F1 Score: {avg_rouge_l_f1:.4f}\")\n    \n    # End of epoch timer\n    epoch_end_time = time.time()\n    epoch_duration = epoch_end_time - epoch_start_time\n    print(f\"Epoch {epoch + 1}, Total Epoch Duration: {epoch_duration:.2f} seconds\")\n\n# End overall timer\noverall_end_time = time.time()\noverall_duration = overall_end_time - overall_start_time\nprint(f\"Overall Training Duration: {overall_duration:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:37:25.083945Z","iopub.execute_input":"2025-02-14T05:37:25.084269Z","iopub.status.idle":"2025-02-14T07:03:29.567693Z","shell.execute_reply.started":"2025-02-14T05:37:25.084244Z","shell.execute_reply":"2025-02-14T07:03:29.566714Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Training Loss: 0.1687\nEpoch 1, Training Duration: 954.77 seconds\nEpoch 1, Validation Loss: 0.1677\nEpoch 1, ROUGE-L-SQL F1 Score: 0.4067\nEpoch 1, Total Epoch Duration: 1723.02 seconds\nEpoch 2, Training Loss: 0.1655\nEpoch 2, Training Duration: 953.36 seconds\nEpoch 2, Validation Loss: 0.1664\nEpoch 2, ROUGE-L-SQL F1 Score: 0.4392\nEpoch 2, Total Epoch Duration: 1721.41 seconds\nEpoch 3, Training Loss: 0.1640\nEpoch 3, Training Duration: 952.15 seconds\nEpoch 3, Validation Loss: 0.1664\nEpoch 3, ROUGE-L-SQL F1 Score: 0.4497\nEpoch 3, Total Epoch Duration: 1720.05 seconds\nOverall Training Duration: 5164.47 seconds\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Save the LoRA adapter weights\nmodel.save_pretrained(\"./lora_sql_model\")\ntokenizer.save_pretrained(\"./lora_sql_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T07:03:37.709096Z","iopub.execute_input":"2025-02-14T07:03:37.709360Z","iopub.status.idle":"2025-02-14T07:03:37.889069Z","shell.execute_reply.started":"2025-02-14T07:03:37.709337Z","shell.execute_reply":"2025-02-14T07:03:37.888228Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"('./lora_sql_model/tokenizer_config.json',\n './lora_sql_model/special_tokens_map.json',\n './lora_sql_model/tokenizer.json')"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# Ensure the model is in evaluation mode\nmodel.eval()\n\n# Move the model to the appropriate device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Define input text (example: partial SQL query)\ntest_input = \"SELECT * FROM products JOIN \"\n\n# Tokenize the input\ninput_ids = tokenizer(test_input, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n\n# Generate output using the model's generate method\nwith torch.no_grad():  # Disable gradient computation during inference\n    generated_tokens = model.generate(\n        **input_ids,\n        max_length=256,  # Allow sufficient length for the model to generate a meaningful continuation\n        num_return_sequences=1,\n        pad_token_id=tokenizer.pad_token_id,\n        eos_token_id=tokenizer.eos_token_id,\n        do_sample=True,  # Enable sampling for more diverse outputs\n        top_k=50,       # Top-k sampling\n        top_p=0.95,     # Nucleus sampling\n        temperature=0.1 # Controls randomness (lower values make outputs more deterministic)\n    )\n\n# Decode the generated tokens back to text\nfull_generated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n\n# Extract only the newly generated part (completion of the query)\ninput_length = len(tokenizer.decode(input_ids.input_ids[0], skip_special_tokens=True))\ngenerated_completion = full_generated_text[input_length:].strip()\n\n# Truncate the completion at the first semicolon (;)\nif ';' in generated_completion:\n    generated_completion = generated_completion.split(';')[0].strip() + ';'\n\nprint(f\"Input: {test_input}\")\nprint(f\"Generated Completion: {generated_completion}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T07:05:58.984891Z","iopub.execute_input":"2025-02-14T07:05:58.985205Z","iopub.status.idle":"2025-02-14T07:06:06.241977Z","shell.execute_reply.started":"2025-02-14T07:05:58.985180Z","shell.execute_reply":"2025-02-14T07:06:06.241176Z"}},"outputs":[{"name":"stdout","text":"Input: SELECT * FROM products JOIN \nGenerated Completion: suppliers ON products.supplier_id = suppliers.supplier_id -> LEFT JOIN categories ON products.category_id = categories.category_id WHERE products.product_id < 15 AND products.product_id < 24;\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"generated_query = test_input + ' ' + generated_completion\n\nnorm1 = similarity.normalize_query(generated_query)\nmax_similarity = 0\nmost_similar_query = \"\"\n\nfor query2 in tqdm(sql_queries):\n    norm2 = similarity.normalize_query(query2)  \n    ast_sim = similarity.ast_similarity(norm1, norm2)\n    component_sim = similarity.component_similarity(norm1, norm2)\n    combined_score = (\n        0.4 * ast_sim + \n        0.3 * component_sim.get(\"tables\", 0) +\n        0.2 * component_sim.get(\"columns\", 0) +\n        0.1 * component_sim.get(\"conditions\", 0)\n    )\n    if combined_score > max_similarity:\n        max_similarity = combined_score\n        most_similar_query = query2\n\nprint(\"Generated query: \\n\", generated_query, '\\n')\nprint(\"Most similar query: \\n\", most_similar_query, '\\n')\nprint(\"Similarity of components: \", max_similarity)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T07:06:10.077281Z","iopub.execute_input":"2025-02-14T07:06:10.077568Z","iopub.status.idle":"2025-02-14T07:06:34.978839Z","shell.execute_reply.started":"2025-02-14T07:06:10.077546Z","shell.execute_reply":"2025-02-14T07:06:34.977973Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 5000/5000 [00:24<00:00, 200.88it/s]","output_type":"stream"},{"name":"stdout","text":"Generated query: \n SELECT * FROM products JOIN  suppliers ON products.supplier_id = suppliers.supplier_id -> LEFT JOIN categories ON products.category_id = categories.category_id WHERE products.product_id < 15 AND products.product_id < 24; \n\nMost similar query: \n SELECT *\nFROM products\n JOIN suppliers ON products.supplier_id = suppliers.supplier_id\n JOIN categories ON products.category_id = categories.category_id\nWHERE products.supplier_id > 645 AND products.product_id < 913; \n\nSimilarity of components:  0.7704892966360857\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}